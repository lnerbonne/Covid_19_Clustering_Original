---
title: "Covid 19 Clustering and Effects on Disabled Communities in August, 2020"
author: "Lucas Nerbonne"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs") })
nocite: '@*'
bibliography: "../../software.bib"
---

# Abstract

This is a attempted partial reproduction study of J. Chakraborty's 2021 study *'Social inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S.'*. 
In it, I'll reproduce Chakraborty's workflow extracting the covid incidence rate for different disability demographic groups, assessing the correlation between county-level case incidence and the population of these demographics. This section of the study uses Covid case data from August 1st, 2020. Because this was so early in the pandemic, spread across space definitely plays a role in case incidence. To account for this Chakraborty creates high incidence clusters as a spatial variable input to Generalized Estimating Equations.

Instead of running GEE's, I'll deviate from Chakraborty's work by clustering county-level cases using kulldorf spatial filtering to generate case clusters and assess spatial scale of Covid spread. This will also serve as a test of the comperability of the spatialepi and SATSCAN implementation of this test, a potentially useful tool for open-source reproductions of epidemiological studies that utilize kulldorff statistics. 

Chakraborty, J. 2021. Social inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S. *Disability and Health Journal* **14**:1-5. DOI:[10.1016/j.dhjo.2020.101007](https://doi.org/10.1016/j.dhjo.2020.101007)


# Study metadata

- `Key words`: Epidemiology, Disease Spread, Disabilities, Covid 19
- `Subject`: Social and Behavioral Sciences: Geography: Human Geography
- `Date created`: 3/3/25
- `Date modified`: 3/3/25
- `Spatial Coverage`: United States of America
- `Spatial Resolution`: Counties
- `Spatial Reference System`: EPSG:4326
- `Temporal Coverage`: March 2020 - August 2020
- `Temporal Resolution`: All recorded Covid 19 cases from the beginning of the pandemic through August 1st, 2020

## Original study spatio-temporal metadata

- `Spatial Coverage`: The 49 contiguous states in the U.S.
- `Spatial Resolution`: Counties
- `Spatial Reference System`: N/A
- `Temporal Coverage`: 1/22/20 - 8/1/2020
- `Temporal Resolution`: All recorded Covid 19 cases from the beginning of the pandemic through August 1st, 2020.
 The data on disability and sociodemographic characteristics come from the U.S. Census American Community Survey (ACS) five-year estimates for 2018 (2014-2018)

# Study design

This work is a partial **reproduction study** to assess the feasibility of reproduction of geographic research. 
Because the original study is likely unable to be replicated perfectly solely from the avalible manuscript, planned deviations will change the end result of the study. 
I have two goals for this study: 

1) To assess the correlation between disabled populations and covid 19 incidence rate in the initial pandemic surge, mirroring Chakraborty's methods to ensure validity.
2) assess the clustering of case incidence between counties, with particular intent to assess the comparability of the spatialepi and SATSCAN implementation of clustering. 

A successful study result will be able to reach similar findings to Chakraborty in relation to the correlation between disability and incidence rate, 
as well as create county clusters of high covid incidence using kulldorf filtering to compare to the original SATSCAN output. 

The original study is a **observational** study that seeks to answer the question "is Covid 19 incidence higher in counties that have a higher percentage of disabled population?".
This research question is ultimately broke into 5 specific hypothesis, investigating whether people with disabilities are effected differently depending on their race, ethnicity, poverty level, age, and biological sex.

The original study was conducted in ArcGIS and SaTScan software; in this reproduction I'll attempt to match methods using R instead. 

# Materials and procedure

## Computational environment

```{r environment-setup, include = FALSE}
# record all the packages you are using here
# this includes any calls to library(), require(),
# and double colons such as here::i_am()
packages <- c("tidyverse", "here", "sf", "pastecs","kableExtra", "tmap", "SpatialEpi", "tidycensus")

# force all conflicts to become errors
# if you load dplyr and use filter(), R has to guess whether you mean dplyr::filter() or stats::filter()
# the conflicted package forces you to be explicit about this
# disable at your own peril
# https://conflicted.r-lib.org/
require(conflicted)
conflicts_prefer(tidyr::extract)
# load and install required packages
# https://groundhogr.com/
if (!require(groundhog)) {
  install.packages("groundhog")
  require(groundhog)
}

# this date will be used to determine the versions of R and your packages
# it is best practice to keep R and its packages up to date
groundhog.day <- "2025-03-7"

# this replaces any library() or require() calls
groundhog.library(packages, groundhog.day)
# you may need to install a correct version of R
# you may need to respond OK in the console to permit groundhog to install packages
# you may need to restart R and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# record the R processing environment
# alternatively, use devtools::session_info() for better results
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# save package citations
knitr::write_bib(c(packages, "base"), file = here("software.bib"))

# set up default knitr parameters
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(
  echo = TRUE, message= FALSE, warnings= FALSE, 
  fig.retina = 4,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)
```

## Data and variables

All variables in this study were derived from secondary data.
There are no experimentally manipulated variables in this experiment.
Eighteen independent variables, a percentage of total disabled persons per county and seventeen 'disaggregated' categories that break down socio-demographic characteristics of the disabled population.
COVID-19 incidence rate can be seen as the dependent variables.

### US CENSUS American Community Survey

- `Title`: County Level Poverty and Disability Data, Derived from 2014-2018 American Community Survey 5-year Estimates
- `Abstract`: This dataset documents poverty and disability data on the county level. The US Census Bureau collects the data in order to produces information on social, economic, housing, and demographic characteristics about the nation's population every year, which provides an important tool for communities to use and see how they are changing. 
- `Spatial Coverage`: United States, OSM [link](https://www.openstreetmap.org/relation/148838#map=3/36.46/-80.16)
- `Spatial Resolution`: Specify the spatial resolution as a scale factor, description of the level of detail of each unit of observation (including administrative level of administrative areas), and/or or distance of a raster GRID size
- `Spatial Representation Type`: Specify the model of spatial data representation, e.g. one of `vector`, `grid`, `textTable`, `tin` (triangulated irregular network), etc. If the type is `vector`, also specify the geometry type as in the OGC Simple Feature Access standard (https://www.ogc.org/publications/standard/sfa/) , e.g. `POINT`, `LINESTRING`, `MULTIPOLYGON`, etc. 
- `Spatial Reference System`: Specify the geographic or projected coordinate system for the study
- `Temporal Coverage`: 2014-2018
- `Lineage`: We computed the summary statistics, including the min, max, mean, and standard deviation. We processed the data after retrieving it by excluding states that irrelevant to our study area. We also checked for data duplication and omission: we found one county with missing disability and poverty data, for which we replaced the missing data with zeros.
- `Distribution`: The data is avalible for download from the US Census
- `Constraints`: The US Census Data is open access in the public domain. 

The variables in question are as follows, with the associated description from the ACS 5 year estimate data which is publicly available [online](https://www.census.gov/topics/health/disability/guidance/data-collection-acs.html): 

Variable Name in Study | ACS Variable name
--- | ---
percent of total civilian non-institutionalized population with a disability | S1810_C03_001E
**Race** |
percent w disability: White alone | S1810_C03_004E
percent w disability: Black alone | S1810_C0 3_005E
percent w disability: Native American | S1810_C03_006E
percent w disability: Asian alone | S1810_C03_007E
percent w disability: Other race | S1810_C03_009E
**Ethnicity** |
percent w disability: Non-Hispanic White | S1810_C03_0011E
percent w disability: Hispanic | S1810_C03_012E
percent w disability: Non-Hispanic non-White | (S1810_C02_001E - S1810_C02_011E - S1810_C02_012E) / (S1810_C01_001E - S1810_C01_011E - S1810_C01_012E) * 100
percent w disability: Other race | S1810_C03_009E
**Poverty** |
percent w disability: Below poverty level | (C18130_004E + C18130_011E + C18130_018E) / C18130_001E * 100
percent w disability: Above poverty level | (C18130_005E + C18130_012E + C18130_019E) / C18130_001E * 100
**Age** |
percent w disability: 5-17 | S1810_C03_014E
percent w disability: 18-34 | S1810_C03_015E
percent w disability: 35-64 | S1810_C03_016E
percent w disability: 65-74 | S1810_C03_017E
percent w disability: 75+ | S1810_C03_018E
**Biological sex** |
percent w disability: male | S1810_C03_001E
percent w disability: female | S1810_C03_003E

```{r calling acs data, echo= FALSE, eval=FALSE}
#this code was used to pull data- due to long run times it's set to not run automatically. 

acs <- get_acs(
  geography = "county",
  table = "S1810",
  year = 2018,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE
)

acs <- filter(acs, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070) %>%
  st_make_valid()

# Query poverty and disability data
acs_pov <- get_acs(
  geography = "county",
  table = "C18130",
  year = 2018,
  output = "wide",
  cache_table = TRUE
)

state <- get_acs(
  geography = "state",
  year = 2018,
  variables = c("B01001_001"),
  geometry = TRUE,
  keep_geo_vars = TRUE
)
# Remove Alaska, Hawaii & Puerto Rico,
state <- dplyr::filter(state, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070)

saveRDS(acs, here("data", "raw", "public", "acs.RDS"))
saveRDS(acs_pov, here("data", "raw", "public", "acs_pov.RDS"))
saveRDS(state, here("data", "raw", "public", "state.RDS"))
```

```{r get state, echo=FALSE, warning=FALSE, results= FALSE}
state <- get_acs(
  geography = "state",
  year = 2018,
  variables = c("B01001_001"),
  geometry = TRUE,
  keep_geo_vars = TRUE
)
state <- dplyr::filter(state, !STATEFP %in% c("02", "15", "72")) %>%
  st_transform(5070)
```

```{r load saved data, echo= FALSE}
#load disability data
acs<- read.csv(here("data","raw","public","disability_raw.csv"))
#load poverty data
acs_pov<- read.csv(here("data","raw","public","poverty_raw.csv"))
```

### JHU Covid Case Dashboard

- `Title`: County Level COVID-19 Incidence Rate
- `Abstract`: This is the data repository for the 2019 Novel Coronavirus Visual Dashboard operated by the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE)
- `Spatial Coverage`: United States, OSM [link](https://www.openstreetmap.org/relation/148838#map=3/36.46/-80.16)
- `Spatial Resolution`: Counties
- `Spatial Representation Type`: Vector Polygon
- `Spatial Reference System`: Mercator
- `Temporal Coverage`: 1/22/20-8-1-20
- `Temporal Resolution`: N/A
- `Lineage`: The specific dataset used was provided by Chakraborty and was been preprocessed in RStudio for analysis. There is no readily apparent way to access archived data from the Johns Hopkins University Center for Systems Science Engineering database. Archived data versions can be found at the John Hopkins CCSE COVID-19 Data Repository ([https://github.com/CSSEGISandData/COVID-19](https://github.com/CSSEGISandData/COVID-19)).
However, archived data only provides summaries at the national scale.

We selected columns that are relevant to our analysis to simplify the stored data, retaining POP_ESTIMA and Confirmed. These columns were then renamed to `pop` and `cases` respectively.
We then calculated the COVID rate by dividing cases with the total population. 
Finally, the geometry of the dataset was dropped. 
- `Distribution`: The data is publically available from the JHU website.
- `Constraints`: The data is open access under the Creative Commons Attribution 4.0 International (CC BY 4.0) by the Johns Hopkins University on behalf of its Center for Systems Science in Engineering. Copyright Johns Hopkins University 2020

```{r covid read in, echo=FALSE}
covid <- st_read(here("data","raw","public","covidcase080120.gpkg"))

covid <- select(covid,
  fips = FIPS,
  pop = POP_ESTIMA,
  cases = Confirmed,
  x = X, y = Y
)
```

## Prior observations  

At the time of this study pre-registration, the authors had prior knowledge of the geography of the study region with regards to the geographic, population, and historical disease spread phenomena to be studied.

For each primary data source, declare the extent to which authors had already engaged with the data:

- [X] no data collection has started
- [ ] pilot test data has been collected
- [ ] data collection is in progress and data has not been observed
- [ ] data collection is in progress and __% of data has been observed
- [ ] data collection is complete and data has been observed. Explain how authors have already manipulated / explored the data.


## Bias and threats to validity

Extensive knowledge of the physical and social geography of the United States might mean that some conclusions drawn will be influenced by prior knowledge of movement patterns ect. 
Additionally, lived experience throughout the course of the pandemic may bias interpretation of patterns in the data. 

From a data side, reporting and testing of cases was notoriously inconsistent across municipalities, states, and regions. 
This means that some counties will likely be incorrectly reported, and that inconsistencies are often correlated (a whole state de-emphasizing testing, resulting in low case counting)


## Data transformations

### ACS
I will first work with data from the ACS- specifically tables acs_vars_S1810 for disability data and acs5_c18130 for poverty data. Using mutate, I'll be able to create a population percentage with disabilities by dividing the number of reported disabilities by total population that there exists a disability designation for.

This specifically is NOT the total population, as the total number of disability vs. no disability answers is less than the total population of counties. 

```{r filter-join-acs}
# Join poverty data to disability data
acs <- acs %>% left_join(acs_pov, by = "GEO_ID")

# calculate percentages
acs_derived <- mutate(acs,
  dis_pct = S1810_C02_001E / S1810_C01_001E * 100,
  white_pct = S1810_C02_004E / S1810_C01_001E * 100,
  black_pct = S1810_C02_005E / S1810_C01_001E * 100,
  native_pct = S1810_C02_006E / S1810_C01_001E * 100,
  asian_pct = S1810_C02_007E / S1810_C01_001E * 100,
  other_pct =
    (S1810_C02_008E + S1810_C02_009E + S1810_C02_010E) / S1810_C01_001E * 100,
  non_hisp_white_pct = S1810_C02_011E / S1810_C01_001E * 100,
  hisp_pct = S1810_C02_012E / S1810_C01_001E * 100,
  non_hisp_non_white_pct =
    (S1810_C02_001E - S1810_C02_012E - S1810_C02_011E) / S1810_C01_001E * 100,
  bpov_pct = (C18130_004E + C18130_011E + C18130_018E) / C18130_001E * 100,
  apov_pct = (C18130_005E + C18130_012E + C18130_019E) / C18130_001E * 100,
  pct_5_17 = S1810_C02_014E / S1810_C01_001E * 100,
  pct_18_34 = S1810_C02_015E / S1810_C01_001E * 100,
  pct_35_64 = S1810_C02_016E / S1810_C01_001E * 100,
  pct_65_74 = S1810_C02_017E / S1810_C01_001E * 100,
  pct_75 = S1810_C02_018E / S1810_C01_001E * 100,
  male_pct = S1810_C02_002E / S1810_C01_001E * 100,
  female_pct = S1810_C02_003E / S1810_C01_001E * 100
)

# select only relevant geographic identifiers and derived percentages. Subsetting strings to select only the last 5 digits, which is the FIPS code format used by the JHU data
acs_derived <- acs_derived %>%
  mutate(fips = substr(GEO_ID, nchar(GEO_ID) - 4, nchar(GEO_ID))) %>%
  select(
    fips,
    statefp = STATE.x,
    county = NAME.x,
    county_st = NAME.x,
    contains("pct")
  )

```


#JHU Covid Data 

Then, I'll calculate case rate per 100,000 people and divide the JHU covid data with rate data into two products- one with and one without geometry. Having geometry associated with the data breaks things a few steps down the line, so it's easier to just remove it in one of the versions now. I'll then join the JHU Covid Case Rate data to the ACS data.

```{r}
covid_mapping <- covid |>
  mutate(covid_rate = round(covid$cases / covid$pop * 100000, 2))

covid_table <- covid_mapping|>
  st_drop_geometry()
```


Here's the resulting map, which is a match to Chakraborty's Figure 1. Below, I also map disability rates by county which is something that Chakraborty didn't do but that helps to visualize spatial patterns across counties. 


```{r covid case mapping, echo= FALSE}
tm_covid_rates<-tm_shape(covid_mapping)+
tm_polygons(fill= "covid_rate",
    title = "COVID-19 Cases per 100,000 people\n(22 January 2020 to 1 August 2020)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "matplotlib.oranges",
  )+
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_covid_rates
```


Now I'll join the JHU dataset to the ACS data by county-level FIPS code, a unique numerical identifier for each county. 

```{r join acs to jhu data}
# Join COVID incidence rate data to acs data
acs_covid <- covid_mapping %>%
  left_join(acs_derived, by = "fips")

# move covid_rate column prior to disability percentages
acs_covid <- acs_covid %>%
  select(fips, statefp, county, county_st, covid_rate, everything())
```

```{r}

tm_disability_rates <- tm_shape(acs_covid) +
  tm_polygons("dis_pct",
    title = "Percent of People with Disability\n(ACS 2014-2018)",
    style = "quantile",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges"
  )+
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_disability_rates
```

It's hard to pick out a discernible correlation/non-correlation from these two maps, so let's dive into the data.


## Analysis


### Statistical Correlation of Disability Rates and Covid Incidence

**Deviation from plan**
I will also calculate descriptive statistics for each disability subgroup to match the original study's methodology/results

**Planned deviation for reanalysis**: I also calculated the Shapiro Wilks test for normality, printed in the table with it's corresponding p value.

```{r descriptive-statistics}
acs_covid_stats <- acs_covid %>%
  st_drop_geometry() %>%
  select(covid_rate, contains("pct")) %>%
  stat.desc(norm = TRUE) %>%
  round(4) %>%
  t() %>%
  as.data.frame() %>%
  select(min, max, mean, SD = std.dev, ShapiroWilk = normtest.W, p = normtest.p)


acs_covid_stats %>%
  kable(caption = "Reproduced Descriptive Statistics",
        align = "c") %>%
  column_spec(2:6, width_min = "5em") %>%
  column_spec(7, width_min = "2em") %>%
  kable_styling(full_width = FALSE)
```

Results from the Shapiro Wilks test indicate strong evidence against normality for the majority of the variables used. This leads us into affirming the results found using the parametric regression with a non-parametric test also. To ensure consistency with Chakraborty's descriptive statistics I'll subtract his summary stats table from mine, with zeros across the board signifying a successful reproduction. `table1` is Chakraborty's table, reconstructed from his published paper. 


```{r compare-descriptive-stats}
# load original table 1 results
table1 <- read.csv(here("data", "raw", "public", "chakraborty", "table1.csv"))

# subtract original results from reproduced results
(select(acs_covid_stats, min, max, mean, SD) -
  select(table1, min, max, mean, SD)) %>%
  kable(caption = "Descriptive Statistics Comparison",
        align = "c") %>%
  column_spec(2:5, width = "4em") %>%
  kable_styling(full_width = FALSE)
```

These columns are JUST off- it looks like potentially Chakraborty has rounded Covid cases to the whole person, which means that our reproduction is mostly correct but will be a tiny bit skewed. *apov_pct* is also being suspicious, with a higher minimum value in my stats that doesn't match `table1`'s results. 

carrying on... 

I will use cor() to determine the correlation between covid cases and pct disability using pearson's correlation coefficient, running for each disability subgroup. 
P values will then be created for each correlation using the following formulas (as per statistics), assigning them to their respective columns with mutate.

```{r pearsons-correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

pearsons_r <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "pearson", use = "everything") %>%
  as.data.frame() %>%
  select(r = covid_rate) %>%
  mutate(
    t = abs(r) / sqrt((1 - r^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  dplyr::filter(variable != "covid_rate")

pearsons_r %>%
  kable(caption = "Reproduced Pearson's R",
        align = "c") %>%
  column_spec(2:4, width = "4em") %>%
  kable_styling(full_width = FALSE)
```

This looks similar to Chakraborty's final Pearson's table; to compare it, I will find the difference between each table and the significance levels assigned to different variables. 


```{r compare-pearsons-correlation}
# calculate number of significance stars at p < 0.01 and p < 0.05 levels.
pearsons_r <- mutate(pearsons_r, rp_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

# join reproduction coefficients to original study coefficients
correlations <- table1 %>%
  dplyr::filter(variable != "covid_rate") %>%
  dplyr::select(variable, or_r = r, or_stars = stars) %>%
  left_join(select(pearsons_r, variable, rp_r = r, rp_stars), by = "variable")

# find difference between coefficient and stars
correlations <- correlations %>%
  bind_cols(rename_with(
    correlations[, 4:5] - correlations[, 2:3],
    ~ paste0(.x, "_diff")
  ))

# find coefficients with different directions
correlations <- correlations %>% mutate(rp_dir_diff = (rp_r > 0) - (or_r > 0))

correlations %>%
  kable(caption = "Compare reproduced and original Pearson's R",
        col.names = c("Variable", "R", "Sig. Level", "R", "Sig. Level", "R", "Sig. Level", "Direction"),
        align = "c") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Original" = 2, "Reproduced" = 2, "Difference" = 3))
```

This correlation and significance value is the final product for my reproduction of the initial phase of Chakraborty's disability correlation work in this paper. The final table should match the corresponding table in his manuscript, which it does ... mostly. All of the significance values are slightly off from what Chakraborty's original calculation, although the levels are all the same with the exception of `pct_18_34`, which went up in significance when I ran the test. Not sure what the source of this is, but I have checked through the workflow thoroughly so could be attributed to our initial case rounding error. 

**deviation from published plan**

Chakraborty didn't test the assumption of normality that is required for a pearson's correlation test (and the variables are non-normally distributed, as seen in my Shapiro-Wilks test); to adjust for this, I'll conduct a Bivariate nonparametric correlation analysis to ensure the validity of his results. 

```{r spearmans correlation}
df <- sum(!is.na(acs_covid$dis_pct)) - 2

spearmans_rho <- acs_covid %>%
  select(where(is.numeric)) %>%
  st_drop_geometry() %>%
  cor(method = "spearman", use = "everything") %>%
  as.data.frame() %>%
  select(rho = covid_rate) %>%
  mutate(
    t = abs(rho) / sqrt((1 - rho^2) / (df)),
    p = pt(t, df, lower.tail = FALSE)
  ) %>%
  round(3) %>%
  rownames_to_column("variable") %>%
  dplyr::filter(variable != "covid_rate")
```

Compare the Spearman's *rho* correlation coefficients to the reproduced Pearson's *r* correlation coefficients.
Differences are calculated as *Spearman's Rho* - *Pearson's R*.

```{r compare-spearmans-correlation}
# calculate number of significance stars at p<0.01 and P<0.05 levels.
spearmans_rho <- mutate(spearmans_rho, rp_rho_stars = as.numeric(as.character(cut(p,
  breaks = c(-0.1, 0.01, 0.05, 1),
  labels = c(2, 1, 0)
))))

correlations <- correlations[, 1:8] %>%
  left_join(select(spearmans_rho, variable, rp_rho = rho, rp_rho_stars), by = "variable")

corrdiff <- select(correlations, starts_with("rp_rho")) -
  select(correlations, rp_r, rp_stars)

correlations <- correlations %>% bind_cols(rename_with(corrdiff, ~ paste0(.x, "_diff")))
rm(corrdiff)

correlations <- correlations %>% mutate(rp_rho_dir_diff = (rp_rho > 0) - (rp_r > 0))

correlations %>%
  select(variable, rp_r, rp_stars, starts_with("rp_rho")) %>%
  kable(col.names = c("Variable", "R", "Stars", "Rho", "Stars", "Rho - R", "Stars", "Direction"),
        align = "c") %>%
  #column_spec(2:6, width_min = "5em") %>%
  kable_styling() %>%
  add_header_above(c(" " = 1, "Pearson's" = 2, "Spearman's" = 2, "Difference" = 3))
```

Significance changes between the two tests are seen, with native_pct and other_pct being reassigned to the ** significance level and pct_18_34 being bumped down to a * significance. This correlation table, which still shows correlation between various disability and demographic categories and Covid spread, is likely a more correct version of the original study's correlations. 



### Clustering Analysis

For the second section of the methods, I'll attempt to create a map of clusters of counties that have high covid incidence rates. 
This is somewhat of a reproduction of Chakraborty's work in that he used county clusters as an input into generalized estimating equations attempting to account for spatial autocorrelation in his disability analysis. 

To delineate his high-incidence clusters Chakraborty used SATScan, a spatio-temporal statistical software that was developed for the monitoring of diseases that uses spherical great circle distance calculations from the centroid of each county to determine county cluster extents.Chakraborty then used the county clusters as a way to control for spatial variation in disability and covid rates, something that could be done with more common geographical techniques like a spatial regression. While potentially effective in this case, the selection of SATSCAN as the tool to account for spatial correlation is likely a product of Chakraborty's epidemiology background, the discipline SatSCAN is meant to be used for. To attempt to mimic his clustering results using R, I will use a Kulldorff filter in the SpatialEpi R package, a hopefully analogous spatial clustering approach.

To generate clusters, SpatialEpi will use county relative risk (comparing local incidence to global incidence rates) to cluster counties into regional areas of relatively higher risk, grouping counties that have a similarly high risk profile together.
The package will return these primary clusters of high-risk-counties and it's best estimation of any secondary clusters, if they exist. 
To assess the effectiveness of this method, I will map clusters to visually determine if they are accurately modeling the perceived clustering of high risk counties. 


```{r SpatialEpi-Kulldorff, eval = FALSE, fig.width=4, fig.height=4}

start_time <- Sys.time()
covid_geo <- covid_table %>%
  select(x, y) %>%
  latlong2grid()
# latlong2grid creates approximate equidistant cylindrical grid
# could probably reproject to epsg 5070 and create table with x and y

# calculate expected cases with one strata
expected.cases <- expected(covid_table$pop, covid_table$cases, 1)

# Kulldorff spatial scan statistic
covid_kulldorff <- kulldorff(
  geo = covid_geo,
  cases = covid_table$cases,
  population = covid_table$pop,
  expected.cases = expected.cases,
  pop.upper.bound = 0.5,
  n.simulations = 999,
  alpha.level = 0.05,
  plot = TRUE
)

print(
  paste(
    "Run time:",
    round(difftime(Sys.time(), start_time, units = "mins"), 2),
    "minutes"
  ),
  quote = FALSE
)


# save results in a file appended with the current date
saveRDS(covid_kulldorff,
  file = here("data", "derived", "public", paste0("covid_kulldorff_", Sys.Date(), ".RDS"))
)
```

```{r load-Kulldorff, echo=FALSE}
# load pre-calculated Kulldorff results
# alternatively, modify the file name with an appended date to load a more current set of results
covid_kulldorff <- readRDS(
  here("data", "derived", "public", "covid_kulldorff_2025-03-27.RDS")
)
```

```{r report-Kulldorff, echo=FALSE}
print("Most likely cluster:", quote = FALSE)
covid_kulldorff$most.likely.cluster
print(
  paste0(
    "Number of Secondary clusters: ",
    length(covid_kulldorff$secondary.clusters)
  ),
  quote = FALSE
)
```


I'll first match the FIPS code of each assumed cluster to the FIPS codes of counties found in covid_table, the non-geometry DF verson of the JHU covid data. From these matched clusters and FIPS codes I'll be able to map the assessed clusters qualitatively. This map should match Chakraborty's clustering data that he inputted to his GEEs. 

```{r}
# list of primary cluster counties
primary_cluster_fips <- covid_kulldorff$most.likely.cluster$location.IDs.included

clusters <- data.frame(
    fips = covid_table[primary_cluster_fips, "fips"],
    clusterID = covid_table[primary_cluster_fips[1], "fips"],
    likelihood = covid_kulldorff$most.likely.cluster$log.likelihood.ratio,
    stringsAsFactors = FALSE
  )
# Get a list of secondary clusters
secondary <- covid_kulldorff$secondary.clusters

# similarly add counties in each secondary cluster to the list of clusters
for (i in secondary) {
  cluster_locations <- i$location.IDs.included
  new_clusters <- data.frame(
    fips = covid_table[cluster_locations, "fips"],
    clusterID = covid_table[cluster_locations[1], "fips"],
    likelihood = i$log.likelihood.ratio,
    stringsAsFactors = FALSE
  )
  clusters <- rbind(clusters, new_clusters)
}

```

Joining the cluster data back to the `acs_covid` dataframe

```{r join-clusterID-to-acs_covid}

acs_covid <- acs_covid %>%
  left_join(clusters, by = "fips") 

acs_covid<-acs_covid|>
  mutate(isCluster = case_when(
    clusterID == fips ~ "center of cluster",
    !is.na(clusterID) ~ "other part of cluster",
    .default = NA
  ))
  
```

**Planned deviation for reproduction**: Map the `SpatialEpi` cluster results.

```{r map-clusters}
acs_covid <- st_as_sf(acs_covid)

tm_spatialepi_clusters <-
  tm_shape(acs_covid) +
  tm_polygons(col = "isCluster",
          palette = "-Oranges",
          popup.vars = c("fips", "clusterID"),
          colorNA = "grey",
          title = "SpatialEpi Kulldorff COVID-19 Clusters",
          border.col = "white",
          lwd = 0.2,
          border.alpha = 0.2) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_clusters
```
This map shows our extracted covid clusters, with the center county of the cluster in red and the counties within the cluster shown in cream. On first pass, we see a huge cluster in the sounteast centered in the Florida Panhandle, spreading through much of the south. We also see several single-county clusters, especially in the more sparsely populated Midwest and West. These are likely by themselves because the surrounding regions lack the popultaion density to spread Covid effectively. 

I'll now calculate the relative risk, a product of Chakraborty's SATSCAN analysis but not of the SpatialEpi R package. This will need to be grouped by cluster to match the final SatScan output. 


```{r relative-risk}
total_pop <- sum(acs_covid$pop)
total_cases <- sum(acs_covid$cases)

acs_covid <- acs_covid %>%
  group_by(clusterID) %>%
  mutate(
    rr_cluster = ifelse(is.na(clusterID), NA,
      (sum(cases) / sum(pop)) / ((total_cases - sum(cases)) / (total_pop - sum(pop)))
    )
  ) %>%
  ungroup() %>%
  mutate(
    rr_loc = (cases / pop) / ((total_cases - cases) / (total_pop - pop))
  )
```

Relative risk will be classified on a scale from 1 to 6.

| Relative Risk Values | Relative Risk Class |
|:--------------------:|:-------------------:|
|  Outside of cluster  |          1          |
|       RR \< 1        |          1          |
|    1 \<= RR \< 2     |          2          |
|    2 \<= RR \< 3     |          3          |
|    3 \<= RR \< 4     |          4          |
|    4 \<= RR \< 5     |          5          |
|    5 \<= RR \< 6     |          6          |

Counties falling outside of any cluster are assigned a score of 1.

```{r classify-relative-risk}
# class breaks
breaks <- c(-Inf, 1, 2, 3, 4, 5, Inf)

acs_covid <- acs_covid %>%
  mutate(
    cluster_class = ifelse(is.na(clusterID), 1, cut(rr_cluster, breaks, labels = FALSE)),
    loc_class = cut(rr_loc, breaks, labels = FALSE)
  )
```

### Map relative risk scores

Let's visualize these relative risk scores spatially!

First, map the spatial distribution of local relative risk score classifications by county.

```{r map local relative risk score}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(loc_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$loc_class,
                           " (",
                           class_freq$n,
                           class_freq$qual,
                           ")")

# Map Local Relative Risk scores
tm_spatialepi_local_risk_class <- tm_shape(acs_covid) +
  tm_polygons("loc_class",
    title = "Local Relative Risk Class",
    border.col = "white",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    style = "cat",
    labels = class_freq$label
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

tm_spatialepi_local_risk_class
```
Next, I map the cluster relative risk scores for comparison.
Note that following the original study classification methodology, counties outside of clusters are assigned the lowest risk class of `1`.

```{r map-cluster-relative-risk-classes}
# count the frequency of counties in each class and create labels
class_freq <- acs_covid %>% st_drop_geometry() %>% count(cluster_class)
class_freq$qual <- ifelse(class_freq$n > 1, " counties", " county")
class_freq[1, ]$qual <- paste(class_freq[1, ]$qual, "at low risk")
class_freq[nrow(class_freq), ]$qual <- paste(class_freq[nrow(class_freq), ]$qual, "at high risk")
class_freq$label <- paste0(class_freq$cluster_class,
                           " (",
                           class_freq$n,
                           class_freq$qual,
                           ")")

# map cluster relative risk scores
tm_spatialepi_cluster_risk_class <- tm_shape(acs_covid) +
  tm_polygons("cluster_class",
    title = "Cluster Relative Risk Class",
    border.col = "white",
    border.alpha = .2,
    lwd = 0.2,
    palette = "Oranges",
    style = "cat",
    labels = class_freq$label
  ) +
  tm_shape(state) +
  tm_borders("grey", lwd = .5) +
  tm_layout(
    legend.position = c("left", "bottom"),
    legend.title.size = 0.8,
    legend.text.size = 0.5
  )

rm(class_freq)

tm_spatialepi_cluster_risk_class
```

We can see that the cluster relative risk does a decent job of describing the overall relative risk, with our large southeast cluster capturing a lot of the higher risk across the region. Isolated clusters in the Midwest also capture spatial differences in relative risk, with different risks seen in adjacent cluster. 

To properly compare the SpatialEpi results to the SATSCAN output, we should probably know how many clusters we have. I'm going to count em and calculate the cluster with the largest number of included counties. The original study found 102 unique clusters with between 1 and 255 counties in each cluster. 

```{r make-gee-clusters}

# summarize clustering results
# summarize clustering results
cluster_summary <- acs_covid %>%
  drop_na(clusterID)|>
  dplyr::filter(cases > 0) %>%
  st_drop_geometry() %>%
  count(clusterID)
cat(
  length(cluster_summary$n),
  "unique clusters based on spatialEpi CLUSTER relative risk\n"
)
 
summary(cluster_summary$n)
rm(cluster_summary)
```

We failed to reproduce the SATSCAN output, producing 133 unique clusters with between 1 and 599 counties, many more than the original output. This is a interesting result, potentially pointing to our implementation of the Kulldorf Scan Statistic differing from SATSCANS. One hypothesis is that it is clustering more sensitively to lower levels of risk, as seen in the southeast megacluster (clusterID 12005), centered on Bay County, Florida. At the same time as we see more preferential grouping into clusters, we also see the sheer numbers of clusters increase. This suggests that spatialepi is, in addition to being more willing to group counties together, happy to initialize more clusters. 

# Discussion

Because this study seeks to both A) Reproduce the first part of Chakraborty's work, assessing for validity and B) use our own methodology to recreate clustering done in an external program, analysis will be split into two sections. The first will explore the correlation between disability rate at the county scale and incidence - if there is a relationship between the disability subcategories and covid incidence like Chakraborty found, we should return significant r values. The second section will compare our finished clusters to Chakraborty's before thinking about why any differences might occur, given that we're using a different program to generate our clusters than he did. I'm not expecting that the clusters will turn out exactly the same, so it'll be interesting to interrogate why any differences arise. 


### Disability Correlation


Agreement was found between our mapped disability data and Chakraborty’s Figure one, producing results without discernible differences. Summary statistics told a relatively similar story, with slight differences, likely in rounding, that reflected minorly different methodology. Specifically, it appeared that Chakraborty rounded Covid cases to the nearest whole person, a step I neglected to stay true to the data. 

After performing Pearson’s correlation on the variables in the data, following Chakraborty’s methods, I subtracted resulting significance values from those presented in the corresponding table in the original paper, which was loaded for comparison. They are mostly identical with similar significance thresholds, but slightly different actual values. This could be attributable to the difference in rounding methodology. The only variable that changed significance threshold was pct_18_34, which changed from significance value 1 to value 2.

Testing the correlation between values using a  bivariate nonparametric correlation test (Spearman’s rho) analysis to assess the validity of Chakraborty’s parametric test used even though the dataset wasn’t normally distributed revealed that several significance values changed, with native_pct and other_pct gaining significance and pct_18_34 being reassigned to a lower (1 star) significance level. 

All in all, this section of the reproduction was a huge success. Despite the rounding issues we were, for the most part able to reproduce Chakraborty’s results, fuifuilling our first goal of reproducing his workflow in open source code. We were also able to add to the analysis by including a test for normality and due to the non-normal distribution of data perform a non-parametric correlation test. This test produced some different results than Chakraborty’s original analysis, deepening the degree of analysis. 


### Clustering 


Implementation of the Kulldorff spatial scan statistic in the spatialepi package instead of SATSCAN was less successful. Clusters were successfully pulled from the data but they did not match the size and number of clusters from the original manuscript. We found more clusters (133 vs 102) and larger clusters (599 vs 255), calling into question the applicability of this package to reproduce the clustering operation of SATSCAN. That being said, the clusters produced do appear to be sensible given the underlying data, so this is likely reflective of a difference in software application instead of an incorrect application of the package. 



# Integrity Statement

This is the only preregistration for this study. 


# Acknowledgements

This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, DOI:[10.17605/OSF.IO/W29MQ](https://doi.org/10.17605/OSF.IO/W29MQ)


# References

Chakraborty, J. 2021. Social inequities in the distribution of COVID-19: An intra-categorical analysis of people with disabilities in the U.S. *Disability and Health Journal* **14**:1-5. DOI:[10.1016/j.dhjo.2020.101007](https://doi.org/10.1016/j.dhjo.2020.101007)